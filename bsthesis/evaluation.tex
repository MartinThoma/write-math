%!TEX root = thesis.tex

\chapter{Evaluation}\label{ch:Evaluation}
A recognition system has two important characteristics: Its recognition accuracy
and the time it needs to recognize a new symbol. Recognition accuracy and time
are measured with new data which was not seen before.

Tests can be divided into two groups: Tests where some examples of the handwriting
of the writer were known at training time and tests were that's not the case.

Known-writer tests are created this way:

\begin{algorithm}[h]
    \begin{algorithmic}
        \State data $\gets k$-dimensional array of Lists
        \State $i \gets 0$
        \State Group labeled datasets by symbol
        \State Filter all symbols that have less than $k$ datasets
        \ForAll{Group $g$ in datasets}
            \ForAll{Dataset $(x, t)$ in $g$}
                \State data[$i$].$\Call{append}{(x, t)}$
                \State $i \gets (i + 1) \mod k$
            \EndFor
        \EndFor
    \end{algorithmic}
\caption{Creation of $k$ bins of datasets}
\label{alg:creation-of-bins}
\end{algorithm}

After that, a $k$-fold cross validation is run:

\begin{algorithm}[h]
    \begin{algorithmic}
        \Function{crossvalidation}{$k$, grouped dataset $d$, classificator $c$}
            \State correct, wrong $\gets 0, 0$
            \State c10, w10 $\gets 0, 0$
            \For{$i \in 0, \dots, k-1$}
                \For{$j \in 0, \dots, k-1$}
                    \If{$i \neq j$}
                        \State $c.\Call{train}{d[i]}$
                    \EndIf
                \EndFor
                \ForAll{$(x, t) \in d[i]$}
                    \Comment List of possible classifications descending by probability
                    \State $L \gets c.\Call{classify}{x}$
                    \If{$L[0] == t$}
                        \State correct $\gets$ correct $+1$
                        \State c10 $\gets$ c10 $+1$
                    \ElsIf{$t \in L$}
                        \State c10 $\gets$ c10 $+1$
                        \State wrong $\gets$ wrong $+1$
                    \Else
                        \State w10 $\gets$ wrong $+1$
                        \State wrong $\gets$ wrong $+1$
                    \EndIf
                \EndFor
            \EndFor
            \State \Return $(\frac{\text{correct}}{\text{correct}+\text{wrong}}, \frac{c10}{c10 + w10})$
        \EndFunction
    \end{algorithmic}
\caption{$k$-fold cross-validaton}
\label{alg:k-fold-cross-validation}
\end{algorithm}

I will call result of such a 10-fold cross-validation
\textit{classification accuracy}. The first part of the tupel is called \textit{Top-1 accuractiy}
and the second one is called \textit{Top-10 accuracy}.

\section{Baseline system: Greedy matching}
The greedy matching algorithm got with scaling and shifting (see \cpageref{alg:scale-and-shift})
a Top-1 accuracy of 83.11\% and a Top-10 accuracy of 97.66\%.