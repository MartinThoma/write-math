%!TEX root = thesis.tex
\chapter{Introduction}\label{ch:Introduction}

\Gls{HWR} is the task of finding a proper textual representation
given a handwritten symbol or sequence of symbols.

In off-line \gls{HWR}, all algorithms have to work on pixel image
information of the handwriting. On-line \gls{HWR} on the other
hand can use the information how symbols were written. This thesis is about
on-line \gls{HWR}.

On-line \gls{HWR} can use techniques of off-line \gls{HWR}, but studies have
showed that on-line information does significantly improve recognition rates
and also simplify algorithms.\cite{Guyon91,Becker72}

\section{Steps in handwriting recognition}
Most handwriting-recognizers perform the following steps in order to recognize
characters, symbols or words:

\begin{enumerate}
    \item \textbf{Preprocessing}: Clean the data. This step is done to get rid
          of information that was either generated due to errors in the hardware %TODO: is that the right way to say it?
          or is not needed at all. The details are explained in
          \cref{sec:preprocessing}.
    \item \textbf{Segmentation}: The task of formula recognition can eventually
          be reduced to the task of symbol recognition combined with symbol
          placement. But before symbol recognition can be done the formula has
          to be segmented. As this thesis % can "bachelors thesis" be abbreviated to thesis?
          is only about single symbol recognition, this step will not be discussed.
    \item \textbf{Feature computiation}: Features is high-level information derived
          from the raw data after preprocessing. Some systems simply take the
          result of the preprocessing step, but many compute new features. This
          might have the advantage that less training data is needed as the
          developer can use a priori knowledge to compute highly discriminative
          features.\\
          Various features will be explained in \cref{sec:features}.
\end{enumerate}

After those steps, it's only a supervised machine learning task that consists of
two parts

\begin{enumerate}
    \item \textbf{Learning}: This is most of the time adjusting parameters.
    \item \textbf{Evaluation} of new datasets.
\end{enumerate}

\section{Mathematical notation}
I will use the notation $v^{(i)}$ when I want to write about the $i$-th element
of a vector $v$. Vectors will always be denoted by lowercase latin letters.

Matrices will be denoted by uppercase latin letters.

The number of training examples will be denoted with $m$, the input vector with
$x$ and the output vector with $y$.

A single training example thus is given by the tuple $(x, y)$.

Weights will be denoted with $W$, hyperparameters with $\theta$.

0-indexed vectors are used.

\section{Limitations of Symbol Recognition}
The recognition capabilities of single symbols are quite limited. There are
many symbols such as \enquote{$\cdot$} and \enquote{.} or \enquote{0}, \enquote{O}
and \enquote{o} that can only be destinguished with context and the availability
of a baseline. As I chose to set up the design of write-math.com without a
baseline and the associated %TODO: is associated correct? "damit verbunden"
restrictions for the user, it is impossible to destingush these characters.
The best that can be done is applying the a priori probabilty.

Preprocessing-operations that cannot be done with a single symbol are

\begin{itemize}
    \item Baseline correction
\end{itemize}