%!TEX root = thesis.tex
\section{Artificial neurons}\label{sec:artificial-neurons}
%% ===========================

Artificial neurons are inspired by biological neurons. Signals are send within 
the cell by charged particles, so called \textit{ions}. But before a biological
neuron sends a signal, a threshold charge has to be reached at the axon
hillock. This threshold charge is called \textit{action potential}. The action
potential can be reached by multiple factors, but the one I want to focus on
are charges send by other neurons. Depending on where the other axon terminals
are located and how long the distance to the axon hillock is, the signal contributes
more or less to reaching the action potential. After that, it simply sends a
signal.

\begin{figure}[ht]
    \centering
    \subfloat[Biological Neuron]{
        \includegraphics*[width=0.48\linewidth, keepaspectratio]{figures/biological-neuron.jpg} 
        \label{fig:biological-neuron}
    }%
    \subfloat[Artificial Neuron]{
        \resizebox{0.45\linewidth}{!}{\input{figures/artificial-neuron.tex}}
        \label{fig:artificial-neuron}
    }%
    \label{fig:artificial-and-biological-neuron}
    \caption{Both neurons receive weighted input, apply a function to that and give output}
\end{figure}

Artificial neurons are similar. They receive at least one input and give at
least one output. Those inputs might get weighted as well as the output.

The neurons apply a function to the sum of all weighted inputs. This function
is also called \textit{activation function}.

An artificial neuron using the unit step function (see \cref{f:unitstep}) is called
a \textit{perceptron}.


The artificial neuron sums all weighted inputs $x_i \cdot w_i$ up
             and applies its activation function $f$ to it.